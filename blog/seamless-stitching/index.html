<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-alpha.63">
<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-176711841-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script><title data-react-helmet="true">Seamless Stitching of Perfect Labels | RoboPickles</title><meta data-react-helmet="true" property="og:title" content="Seamless Stitching of Perfect Labels | RoboPickles"><meta data-react-helmet="true" name="description" content="The previous articles describe how to unwrap labels programmatically and how we"><meta data-react-helmet="true" property="og:description" content="The previous articles describe how to unwrap labels programmatically and how we"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><link data-react-helmet="true" rel="shortcut icon" href="/img/favicon.ico"><link rel="stylesheet" href="/styles.5b62089c.css">
<link rel="preload" href="/styles.d92048b8.js" as="script">
<link rel="preload" href="/runtime~main.7228688e.js" as="script">
<link rel="preload" href="/main.747b34ac.js" as="script">
<link rel="preload" href="/common.40016a44.js" as="script">
<link rel="preload" href="/18.4146caa9.js" as="script">
<link rel="preload" href="/a04b8cd5.5267b6b2.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<nav class="navbar navbar--light navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><a class="navbar__brand" href="/"><img class="navbar__logo" src="/img/logo.svg" alt="RoboPickles"><strong class="navbar__title">RoboPickles</strong></a><a class="navbar__item navbar__link" href="/docs/">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/robopickles/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub</a><div class="react-toggle react-toggle--disabled displayOnlyInLargeViewport_2aTZ"><div class="react-toggle-track"><div class="react-toggle-track-check"><span class="toggle_BsTx">üåú</span></div><div class="react-toggle-track-x"><span class="toggle_BsTx">üåû</span></div></div><div class="react-toggle-thumb"></div><input type="checkbox" disabled="" aria-label="Dark mode toggle" class="react-toggle-screenreader-only"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/"><img class="navbar__logo" src="/img/logo.svg" alt="RoboPickles"><strong class="navbar__title">RoboPickles</strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/docs/">Docs</a></li><li class="menu__list-item"><a aria-current="page" class="menu__link navbar__link--active" href="/blog">Blog</a></li><li class="menu__list-item"><a href="https://github.com/robopickles/" target="_blank" rel="noopener noreferrer" class="menu__link">GitHub</a></li></ul></div></div></div></nav><div class="main-wrapper"><div class="container margin-vert--lg"><div class="row"><div class="col col--8 col--offset-2"><article><header><h1 class="margin-bottom--sm blogPostTitle_1mse">Seamless Stitching of Perfect Labels</h1><div class="margin-vert--md"><time datetime="2020-08-27T00:00:00.000Z" class="blogPostDate_3bQP">August 27, 2020  ¬∑ 5 min read</time></div><div class="avatar margin-vert--md"><div class="avatar__intro"><h4 class="avatar__name"><a href="https://github.com/Nepherhotep/" target="_blank" rel="noreferrer noopener">Alexey Zankevich</a></h4><small class="avatar__subtitle"></small></div></div></header><section class="markdown"><p>The previous articles describe how to unwrap labels programmatically and how we
trained a neural network to detect keypoints.
This article is about how to stitch multiple images into a single long one.</p><p><img alt="logo" src="/assets/images/logo-6888d86f696f3c4d88682f080b31d701.jpg"></p><p>The original set of images (below) was segmented and unwrapped in advance by a
neural network, as described in the previous articles. Please see them for
more detail.</p><p><img alt="multiple unwrap" src="/assets/images/unwrap_multiple_fragments-b3ea49b8c2258d6e956635fcbf0b9b7e.jpg"></p><p>How does stitching even work? We take two images with overlapping areas,
compute the mutual shift from each other, and blend them. Sounds pretty easy,
but let‚Äôs go through each of the steps.
To calculate the shift, it‚Äôs required to find something that exists on both
images, and find a formula to convert points from the first image into points
on the second one. The mentioned shift can be represented by a homography
matrix, where the cell values encode the different types of transformations
together ‚Äî scaling, translation, and rotation.
As we can see, in these photos, there are plenty of common objects:</p><p><img alt="match frames" src="/assets/images/match_frames-ef3cace18ed62b0831d3debfc11a084b.jpg"></p><p>The problem with the given features is that it‚Äôs hard to detect them
programmatically. Luckily, there are algorithms that detect ‚Äúgood‚Äù
features (also known as ‚Äúcorners‚Äù ‚Äî there is an excellent document
that explains them).
One such algorithm is SIFT (Scale-Invariant Feature Transform).
Despite being invented in 1999, it‚Äôs still very popular due to its simplicity
and reliability. Since SIFT is patented, it‚Äôs a part of OpenCV non-free build,
but the patent recently expired (in March 2020), so it will probably become a
part of standard OpenCV soon.
Now, let‚Äôs find similar features on both images:</p><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div tabindex="0" class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">sift = cv2.xfeatures2d.SIFT_create()</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">features_left = sift.detectAndCompute(left_image, None)</span></div></div></div></div></div><p><img alt="left image keypoints" src="/assets/images/left_fragment_keypoints-ce68423fbe7149b1927071909e9d559d.jpg"></p><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div tabindex="0" class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">features_right = sift.detectAndCompute(right_image, None)</span></div></div></div></div></div><p><img alt="right image keypoints" src="/assets/images/right_fragment_keypoints-628dbab2572dcc6807793d3b56c17802.jpg"></p><p>Using a Flann based matcher can find matches relatively quickly between two
images, despite a large number of corners.
The yellow lines in the picture below connect similar features in the left
and right images.</p><p><img alt="fragment matching sift" src="/assets/images/fragment_matching_sift-63f77e5eb8e0d4f01f7ab9548cb49a61.jpg"></p><p>For clarity, the images were placed above each other with the proper offset
(which is calculated at a later point in the process, rather than here).
As it‚Äôs easy to see, there are still lots of mismatches ‚Äî about 50% of them
were wrong. However, the good matches will always generate the same
translation, meantime the bad ones will give chaotically different directions.
A picture below depicts only the good matches:</p><p><img alt="fragment matching sift corrected" src="/assets/images/fragment_matching_sift_corrected-62c2c2db420b9e7f77d07f3af27e3138.jpg"></p><p>One of the approaches to find a proper translation is a RANSAC algorithm.
It goes through the matches iteratively and uses a voting approach to figure
out if the proper translation is already found.
Luckily, OpenCV provides multiple choices to find homography using RANSAC ‚Äî
the difference between methods is in dimensions of freedom the transformation
is going to have. In our case, we need to use estimateAffinePartial2D which
will look for the following transformations: rotation + scaling + translation
(4 dimensions of freedom).</p><div class="mdxCodeBlock_1XEh"><div class="codeBlockContent_1u-d"><button type="button" aria-label="Copy code to clipboard" class="copyButton_10dd">Copy</button><div tabindex="0" class="prism-code language-undefined codeBlock_3iAC"><div class="codeBlockLines_b7E3" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">H, _ = cv2.estimateAffinePartial2D(right_matches, left_matches, False)</span></div></div></div></div></div><p>The left image:
<img alt="left fragment transformed" src="/assets/images/left_fragment_transformed-fa3099ac7d7f55012f659789fec1f6b3.jpg"></p><p>The right image:
<img alt="right fragment transformed" src="/assets/images/right_fragment_transformed-4d385c2902913d7e43a5feb5d82c99f5.jpg"></p><p>Let‚Äôs blend them using a naive method, where the intersected region is
calculated as a mean of left and right images. Unfortunately, the result isn‚Äôt
really impressive ‚Äî there are double vision artifacts across the image,
especially closer to stitches.
<img alt="stitched without optical flow" src="/assets/images/stitched_without_optical_flow-df6bd3cfc5a3fc88c2fc361896c9158e.jpg"></p><p>The animation shows the shift between the tiles:
<img alt="animation stitched" src="/assets/images/stitched_animation-65e8b76a45f88d0d20660ffd7290c9c1.gif"></p><p>It‚Äôs not surprising ‚Äî the images were taken from slightly different angles,
and there are tiny differences between them.
For seamless stitching, it‚Äôs required to compensate for those non-linear
distortions. The distortion can be described as a smooth vector field, with
the same resolution as the original tiles. This vector field is called
‚Äúoptical flow‚Äù.
<img alt="optical flow" src="/assets/images/optical_flow-8483552ed7cce4ad5dfaad0d3c5e7299.png"></p><p>There are several techniques to calculate the flow ‚Äî with functions that come
with OpenCV or special neural network architectures.
Our optical flow for the given two tiles:
To avoid artifacts during stitching, it‚Äôs required to compensate both images
proportionally. For that purpose, we split the optical flow into two matrices:
<img alt="optical flow split" src="/assets/images/optical_flow_split-db9fceb7c34b2769958b369f4e3ee9ed.png"></p><p>Now the two images are almost perfectly aligned:
<img alt="animation optical flow" src="/assets/images/optical_flow_animation-2249a063a92d81db9379ff73b786cc72.gif"></p><p>Once we blend the full image, it appears to be geometrically correct, but we
observe a brightness jump:
<img alt="stitched with optical flow" src="/assets/images/stitched_with_optical_flow-b1c212c5b9931b8f80f58f934faf3efb.jpg"></p><p>The issue is quite easy to fix if, instead of mean values, we use a blending
formula, where the values are applied with the gradient:
<img alt="blending animation" src="/assets/images/blending_animation-3980b6cf8c229fb24afda617ac7d9e8a.gif"></p><p>With that approach, the stitching is absolutely seamless:
<img alt="stitched with blending" src="/assets/images/stitched_with_blend-5b46d2815e11dc4fee7b217f263c9828.jpg"></p><p>There are other blending algorithms that work well with panorama stitching
(such as multiband blending), but they don‚Äôt work well for images with text ‚Äî
only optical flow compensation can completely remove ghosting on characters.</p><p>Let‚Äôs stitch the entire set of images:
<img alt="frames set" src="/assets/images/frames_set-cabda4a843f755e0784576c4f456c28d.jpg"></p><p>The final result:
<img alt="stitched long" src="/assets/images/stitched_long-2a00c2e9fb4014ec38b3d566b0feeb74.jpg"></p><p>Future improvements could be a shadow effect compensation (the right side of
the image), and even doing more post-processing to improve colors and contrast.
Here we learned how stitching works, and how to make it seamless for production
use. The service is available for everyone at Perfect Label as a REST API.</p><p>The recommended links:</p><ul><li>SIFT explained <a href="https://docs.opencv.org/master/da/df5/tutorial_py_sift_intro.html" target="_blank" rel="noopener noreferrer">https://docs.opencv.org/master/da/df5/tutorial_py_sift_intro.html</a></li><li>OpenCV homography explained <a href="https://docs.opencv.org/master/d9/dab/tutorial_homography.html" target="_blank" rel="noopener noreferrer">https://docs.opencv.org/master/d9/dab/tutorial_homography.html</a></li><li>Panorama Autostitching <a href="http://matthewalunbrown.com/papers/ijcv2007.pdf" target="_blank" rel="noopener noreferrer">http://matthewalunbrown.com/papers/ijcv2007.pdf</a></li><li>OpenPano <a href="https://github.com/ppwwyyxx/OpenPano" target="_blank" rel="noopener noreferrer">https://github.com/ppwwyyxx/OpenPano</a></li><li>Google Photo Scanner <a href="https://ai.googleblog.com/2017/04/photoscan-taking-glare-free-pictures-of.html" target="_blank" rel="noopener noreferrer">https://ai.googleblog.com/2017/04/photoscan-taking-glare-free-pictures-of.html</a></li></ul></section><footer class="row margin-vert--lg"><div class="col"><strong>Tags:</strong><a class="margin-horiz--sm" href="/blog/tags/stitching">stitching</a><a class="margin-horiz--sm" href="/blog/tags/perfectlabel">perfectlabel</a></div></footer></article><div><a href="https://github.com/robopickles/blog/2020-08-27-seamless-stitching-of-perfect-labels.mdx" target="_blank" rel="noreferrer noopener"><svg fill="currentColor" height="1.2em" width="1.2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 40 40" style="margin-right:0.3em;vertical-align:sub"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></div><div class="col col--2"><div class="tableOfContents_3SO_"></div></div></div></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><h4 class="footer__title">Docs</h4><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/">Style Guide</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/doc2/">Second Doc</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">Community</h4><ul class="footer__items"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow</a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord</a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">More</h4><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub</a></li></ul></div></div><div class="text--center"><div>Copyright ¬© 2020 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/styles.d92048b8.js"></script>
<script src="/runtime~main.7228688e.js"></script>
<script src="/main.747b34ac.js"></script>
<script src="/common.40016a44.js"></script>
<script src="/18.4146caa9.js"></script>
<script src="/a04b8cd5.5267b6b2.js"></script>
</body>
</html>